K-Mean clustering is an unsupervised classification Model.  What sets it apart from supervised algorithms is the absence of a target variable. In unsupervised learning,the dataset only has input variables which describe the data. 
In this model the clustering is done based on the distance from the centroid point.  The algorithm starts by randomly initializing centroids within the feature space. These centroids serve as the initial cluster centers. Due to the iterative nature of this model, these centerpoints are placed repeatedly and it returns the clusters with the equal variance minimizing a criterion known as the inertia or within-cluster sum-of-squares.
The value of K determines the number of clusters or more technically the number of the centroids. This value is the essence of this model. Beside over fitting or under fitting, If the value k is too small, clusters may be merged together, resulting in larger, less distinct clusters. In other hand, if 𝑘 is too large, there may be many small, tightly packed clusters that don't represent meaningful patterns in the data.
1- Visually: We can recursively increase the value of k and use our model to cluster them and use any visualization to plot all the clustered points in lower dimension. We can visually choose the one that has a disjoint set or clusters. However, visual calculation might not always be optimal.
2- Use elbow method: It is based on the principle that as the number of clusters increases, the variance within each cluster decreases. However, at a certain point, adding more clusters does not significantly decrease the within-cluster variance, resulting in an "elbow" point in the plot of the within-cluster variance against the number of clusters. This elbow point indicates the optimal value of k where increasing the number of clusters beyond that point does not provide much better clustering. 
The "inertia" value in k-means clustering is a measure of how consistent clusters are. It quantifies the compactness of the clusters, with lower inertia indicating tighter clusters. Inertia is also referred to as within-cluster sum of squares (WCSS) or total within-cluster variance.
Mathematically, the inertia of a k-means clustering solution is calculated as the sum of squared distances of each data point to its nearest cluster centroid. It's computed using the following